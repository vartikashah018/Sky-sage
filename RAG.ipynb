{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/astrology-bot/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from interface.inference import get_answer\n",
    "# from model.inference_model import LlaMA2\n",
    "from model.embedding_model import Encoder\n",
    "from RAG.utils import cos_similarity\n",
    "from pinecone import Pinecone\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from RAG.chunk_data import sliding_window\n",
    "from interface.get_response import retrieve_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = ['magician_reversed', 'empress_upright', 'moon_upright']\n",
    "question = f'''Crystal, 24 year-old, single, who just left a company. She wanted to ask a question what she should do for her next job?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "answer, context = get_answer(question=question, cards = cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"As the Magician Reversed appears in your reading, it suggests that you may have been relying too heavily on your logical, rational mind in your search for your next job. While this is important, it's also crucial to tap into your intuition and creativity when making decisions. Consider taking some time to meditate or engage in other mindfulness practices to connect with your inner wisdom. This will help you make decisions that are in alignment with your true desires and values.\\n\\n    As the Empress appears in your reading, it's a sign that abundance and pleasure are on the horizon for you. You may be feeling more creative and inspired in your work, and you may be more attractive to potential employers. Trust in your own worth and value, and don't be afraid to ask for what you want.\\n\\n    As the Moon appears in your reading, it's a reminder that your intuition is a powerful tool in your job search. Pay attention to your gut feelings and inner wisdom, as they may be guiding you towards the right opportunity. However, be cautious of illusions and misinformation that could cloud your judgment. Take the time to research and gather all the facts before making any decisions.\\n\\n    Overall, it's important to trust in your own inner wisdom and creativity when searching for your next job. Don't be afraid to take a step back and connect with your intuition, as this will help you make decisions that are in alignment with your true desires and values.\",\n",
       " \"You are an AI Clairvoyant. The retrieved context may help answer the question.\\n\\n    Context: #0 life. Connect with your senses through taste, touch, sound, smell and sight. Draw on these senses to experience pleasure and deep fulfilment. Treat yourself to a day spa, learn massage, enjoy a fine restaurant or spend more time with your partner. Discover different approaches to expressing yourself creatively, be it through painting, music, drama or other art forms. This may be the perfect chance to take up a new hobby that enables you to access this part of yourself. The Empress signifies abundance. You are surrounded by life’s pleasures and luxuries and have everything you need to live a comfortable lifestyle. You are in a period of growth, in which all you have dreamed of is now coming to fruition. When The Empress appears in your Tarot readings, take a moment to reflect on the bounty that surrounds you and offer gratitude for all you have created so you can continue to build on this energy and create even more abundance in your life. As the Mother Earth archetype, The Empress urges you to venture out into nature to ground your energy and be in flow with the earth. Take a trip to your favorite natural setting, be it a forest, beach, mountain or lake, and sit for a couple of minutes, hours or even days to breathe in the energy that surrounds you while marveling in the beauty of your surroundings. Allow yourself the time and the space to enter a different frame of mind and receive the grounding spirit of nature into your heart and consciousness. When you do this, you can reach higher planes of consciousness. When you are in tune with the energy of The Empress, you will naturally take on her mothering nature. You feel a strong urge to nurture and care for others, from \\n#1 Illusion, fear, anxiety, subconscious, intuition The Moon card shows a full moon in the night’s sky, positioned between two large towers. The Moon is a symbol of intuition, dreams, and the unconscious. Its light is dim compared to the sun, and only slightly illuminates the path to higher consciousness winding between the two towers. In the foreground is a small pool, representing the watery, subconscious mind. A small crayfish crawls out of the pool, symbolizing the early stages of consciousness unfolding. A dog and a wolf stand in the grassy field, howling at the moon, representing both the tamed and the wild aspects of our minds. The Moon represents your fears and illusions and often comes out when you are projecting fear into your present and your future, based on your past experiences. You may have a painful memory that caused emotional distress, and rather than dealing with the emotions you pushed them down deep into your subconscious. Now, these emotions are making a reappearance, and you may find yourself under their influence on a conscious or subconscious level. For example, if you had a car accident when you were young but didn’t deal with the emotions, you may get sad or anxious every time you get into the backseat of a car. To remedy this, connect with your subconscious mind and release any fears or anxieties holding you back. Hypnosis, therapy and shamanic healing can support this process. The Moon can indicate a time of uncertainty and illusion, when nothing is what it seems. Be careful of making fast decisions when The Moon appears because you may later realize you only had half the information you needed. You need to listen to and trust your intuition so you can see beyond what is in front of you. Feel into \\n\\n\\n    Question: Crystal, 24 year-old, single, who just left a company. She wanted to ask a question what she should do for her next job?\\n\\n    Tarot Cards: ['magician_reversed', 'empress_upright', 'moon_upright']\\n\\n    Response to the Question:\\n    \\n    As the Magician Reversed appears in your reading, it suggests that you may have been relying too heavily on your logical, rational mind in your search for your next job. While this is important, it's also crucial to tap into your intuition and creativity when making decisions. Consider taking some time to meditate or engage in other mindfulness practices to connect with your inner wisdom. This will help you make decisions that are in alignment with your true desires and values.\\n\\n    As the Empress appears in your reading, it's a sign that abundance and pleasure are on the horizon for you. You may be feeling more creative and inspired in your work, and you may be more attractive to potential employers. Trust in your own worth and value, and don't be afraid to ask for what you want.\\n\\n    As the Moon appears in your reading, it's a reminder that your intuition is a powerful tool in your job search. Pay attention to your gut feelings and inner wisdom, as they may be guiding you towards the right opportunity. However, be cautious of illusions and misinformation that could cloud your judgment. Take the time to research and gather all the facts before making any decisions.\\n\\n    Overall, it's important to trust in your own inner wisdom and creativity when searching for your next job. Don't be afraid to take a step back and connect with your intuition, as this will help you make decisions that are in alignment with your true desires and values.\",\n",
       " \"You are an AI Clairvoyant. The retrieved context may help answer the question.\\n\\n    Context: #0 life. Connect with your senses through taste, touch, sound, smell and sight. Draw on these senses to experience pleasure and deep fulfilment. Treat yourself to a day spa, learn massage, enjoy a fine restaurant or spend more time with your partner. Discover different approaches to expressing yourself creatively, be it through painting, music, drama or other art forms. This may be the perfect chance to take up a new hobby that enables you to access this part of yourself. The Empress signifies abundance. You are surrounded by life’s pleasures and luxuries and have everything you need to live a comfortable lifestyle. You are in a period of growth, in which all you have dreamed of is now coming to fruition. When The Empress appears in your Tarot readings, take a moment to reflect on the bounty that surrounds you and offer gratitude for all you have created so you can continue to build on this energy and create even more abundance in your life. As the Mother Earth archetype, The Empress urges you to venture out into nature to ground your energy and be in flow with the earth. Take a trip to your favorite natural setting, be it a forest, beach, mountain or lake, and sit for a couple of minutes, hours or even days to breathe in the energy that surrounds you while marveling in the beauty of your surroundings. Allow yourself the time and the space to enter a different frame of mind and receive the grounding spirit of nature into your heart and consciousness. When you do this, you can reach higher planes of consciousness. When you are in tune with the energy of The Empress, you will naturally take on her mothering nature. You feel a strong urge to nurture and care for others, from \\n#1 Illusion, fear, anxiety, subconscious, intuition The Moon card shows a full moon in the night’s sky, positioned between two large towers. The Moon is a symbol of intuition, dreams, and the unconscious. Its light is dim compared to the sun, and only slightly illuminates the path to higher consciousness winding between the two towers. In the foreground is a small pool, representing the watery, subconscious mind. A small crayfish crawls out of the pool, symbolizing the early stages of consciousness unfolding. A dog and a wolf stand in the grassy field, howling at the moon, representing both the tamed and the wild aspects of our minds. The Moon represents your fears and illusions and often comes out when you are projecting fear into your present and your future, based on your past experiences. You may have a painful memory that caused emotional distress, and rather than dealing with the emotions you pushed them down deep into your subconscious. Now, these emotions are making a reappearance, and you may find yourself under their influence on a conscious or subconscious level. For example, if you had a car accident when you were young but didn’t deal with the emotions, you may get sad or anxious every time you get into the backseat of a car. To remedy this, connect with your subconscious mind and release any fears or anxieties holding you back. Hypnosis, therapy and shamanic healing can support this process. The Moon can indicate a time of uncertainty and illusion, when nothing is what it seems. Be careful of making fast decisions when The Moon appears because you may later realize you only had half the information you needed. You need to listen to and trust your intuition so you can see beyond what is in front of you. Feel into \\n\\n\\n    Question: Crystal, 24 year-old, single, who just left a company. She wanted to ask a question what she should do for her next job?\\n\\n    Tarot Cards: ['magician_reversed', 'empress_upright', 'moon_upright']\\n\\n    Response to the Question:\\n    \")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As the Magician Reversed appears in your reading, it suggests that you may have been relying too heavily on your logical, rational mind in your search for your next job. While this is important, it's also crucial to tap into your intuition and creativity when making decisions. Consider taking some time to meditate or engage in other mindfulness practices to connect with your inner wisdom. This will help you make decisions that are in alignment with your true desires and values.\\n\\n    As the Empress appears in your reading, it's a sign that abundance and pleasure are on the horizon for you. You may be feeling more creative and inspired in your work, and you may be more attractive to potential employers. Trust in your own worth and value, and don't be afraid to ask for what you want.\\n\\n    As the Moon appears in your reading, it's a reminder that your intuition is a powerful tool in your job search. Pay attention to your gut feelings and inner wisdom, as they may be guiding you towards the right opportunity. However, be cautious of illusions and misinformation that could cloud your judgment. Take the time to research and gather all the facts before making any decisions.\\n\\n    Overall, it's important to trust in your own inner wisdom and creativity when searching for your next job. Don't be afraid to take a step back and connect with your intuition, as this will help you make decisions that are in alignment with your true desires and values.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[0].split('\\\",')[0].strip('\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = '''\n",
    "# '#0 life. Connect with your senses through taste, touch, sound, smell and sight. \n",
    "# Draw on these senses to experience pleasure and deep fulfilment. \n",
    "# Treat yourself to a day spa, learn massage, enjoy a fine restaurant or spend more time with your partner. \n",
    "# Discover different approaches to expressing yourself creatively, be it through painting, music, drama or other art forms. \n",
    "# This may be the perfect chance to take up a new hobby that enables you to access this part of yourself. \n",
    "# The Empress signifies abundance. You are surrounded by life’s pleasures and luxuries and have everything you need to live a \n",
    "# comfortable lifestyle. You are in a period of growth, in which all you have dreamed of is now coming to fruition. \n",
    "# When The Empress appears in your Tarot readings, take a moment to reflect on the bounty that surrounds you and \n",
    "# offer gratitude for all you have created so you can continue to build on this energy and create even more abundance in \n",
    "# your life. As the Mother Earth archetype, The Empress urges you to venture out into nature to ground your energy and be in \n",
    "# flow with the earth. Take a trip to your favorite natural setting, be it a forest, beach, mountain or lake, and sit for a \n",
    "# couple of minutes, hours or even days to breathe in the energy that surrounds you while marveling in the beauty of your \n",
    "# surroundings. Allow yourself the time and the space to enter a different frame of mind and receive the grounding spirit of \n",
    "# nature into your heart and consciousness. When you do this, you can reach higher planes of consciousness. When you are in \n",
    "# tune with the energy of The Empress, you will naturally take on her mothering nature. You feel a strong urge to nurture \n",
    "# and care for others, from \\n#1 relationships. The arrival of this card in a Tarot reading shows that you have a beautiful,\n",
    "#  soul-honoring connection with a loved one. You may believe you have found your soul mate or life partner, \n",
    "#  and the sexual energy between you both goes way beyond instant gratification and lust to something that is very\n",
    "#    spiritual and almost Tantric. While The Lovers card typically refers to a romantic tie, it can also represent a close friendship or family relationship where love, respect and compassion flow. The Lovers is a card of open communication and raw honesty. Given that the man and woman are naked, they are both willing to be in their most vulnerable states and have learned to open their hearts to one another and share their truest feelings. They shape the container from which trust and confidence can emerge, and this makes for a powerful bond between the two. In a reading, this card is a sign that by communicating openly and honestly with those you care about, you will create a harmonious and fulfilling relationship built on trust and respect. On a more personal level, The Lovers card represents getting clear about your values and beliefs. You are figuring out what you stand for and your philosophy. Having gone through the indoctrination of The Hierophant, you are now ready to establish your belief system and decide what is and what is not essential to you. It’s time to go into the big wide world and make choices for yourself, staying true to who you are and being authentic and genuine in all your endeavors. At its heart, The Lovers is about choice. The choice about who you want to be in this lifetime, \n",
    "# how you connect with others and on what level, and about what you will and won’t \\n'\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "\n",
    "class LlaMA2:\n",
    "    \"\"\"\n",
    "    A class for generating results given questions using a LLaMA-2 model.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint, max_seq_len = 512, device='cuda:0',API_KEY=None):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(checkpoint)\n",
    "        self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        if API_KEY is not None:\n",
    "            self.model = LlamaForCausalLM.from_pretrained(checkpoint,torch_dtype=torch.float16, token = API_KEY).to(self.device)  \n",
    "        else:\n",
    "            self.model = LlamaForCausalLM.from_pretrained(checkpoint,torch_dtype=torch.float16).to(self.device)\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer.encode(text, return_tensors='pt', max_length=self.max_seq_len, truncation=True)\n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        # Calculate the maximum length for the model generation\n",
    "        output_max_length = len(inputs[0]) + self.max_seq_len\n",
    "        \n",
    "        outputs = self.model.generate(inputs, max_length=output_max_length)\n",
    "        full_output =  self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # post-process the model outputs to find a proper answer\n",
    "        answer = full_output.split('Context:')[1]\n",
    "        answer_prefix = \"Response to the Question:\"\n",
    "        start = answer.find(answer_prefix)\n",
    "\n",
    "        # Extract the answer\n",
    "        if start != -1:\n",
    "            start += len(answer_prefix)\n",
    "            answer = answer[start:].strip()\n",
    "        else:\n",
    "            answer = \"Please try again.\"\n",
    "        \n",
    "        return answer, full_output, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, context, inference_model, cards):\n",
    "    \"\"\"\n",
    "    Generates an answer to a given question using a few-shot learning approach and provided context.\n",
    "\n",
    "    :param question: The question to be answered.\n",
    "    :param few_shots: Examples provided to guide the model in the format of few-shot learning.\n",
    "    :param context: The context or background information relevant to the question.\n",
    "    :param inference_model: The model used to infer or predict the answer based on the query.\n",
    "\n",
    "    :return: The predicted answer as a string, expected to be one word among [A, B, C, D].\n",
    "    \"\"\"\n",
    "    \n",
    "    query = f\"\"\"You are an AI Clairvoyant. The retrieved context may help answer the question.\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Tarot Cards: {cards}\n",
    "\n",
    "    Response to the Question:\n",
    "    \"\"\"\n",
    "    \n",
    "    answer = inference_model.predict(query)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.69s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 23.06 MiB is free. Process 13222 has 15.75 GiB memory in use. Of the allocated memory 15.44 GiB is allocated by PyTorch, and 9.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m embedding_model_path \u001b[38;5;241m=\u001b[39m inference_model_path\n\u001b[1;32m      4\u001b[0m inference_model \u001b[38;5;241m=\u001b[39m LlaMA2(inference_model_path, API_KEY\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m),max_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m embedding_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/embeddings.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/astrology-bot/model/embedding_model.py:20\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[0;34m(self, checkpoint, MAX_SEQ_LEN, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(checkpoint)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/transformers/modeling_utils.py:2576\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/workspaces/astrology-bot/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 23.06 MiB is free. Process 13222 has 15.75 GiB memory in use. Of the allocated memory 15.44 GiB is allocated by PyTorch, and 9.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "inference_model_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# embedding_model_path = 'BAAI/bge-large-en-v1.5',\n",
    "embedding_model_path = inference_model_path\n",
    "inference_model = LlaMA2(inference_model_path, API_KEY=os.environ.get(\"HF_TOKEN\"),max_seq_len=512)\n",
    "embedding_model = Encoder(embedding_model_path, 512)\n",
    "embedding_df = pd.read_parquet(\"./data/embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = retrieve_context(question, cards, embedding_df, embedding_model, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, full_output, text = ask_question(question, context, inference_model,cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Crystal, the combination of cards you've drawn suggests that you should take a creative and intuitive approach to finding your next job. The Magician Reversed indicates that you may have been too focused on practicality and logic in your previous job search, and it's time to tap into your inner wisdom and creativity. The Empress Upright represents abundance and nurturing, which aligns with your desire to find a fulfilling and comfortable lifestyle. The Moon Upright symbolizes intuition and the subconscious, suggesting that you should trust your gut instincts and listen to your inner voice when exploring new career opportunities.\\n\\nTo manifest your next job, you may want to consider exploring creative fields such as art, music, or writing. These fields align with your intuition and creativity, and can provide a sense of fulfillment and abundance. Additionally, you may want to consider taking a course or workshop to develop your skills in these areas, as this can help you tap into your inner wisdom and creativity.\\n\\nIn terms of your relationships, the Lovers card suggests that you are ready to open up and communicate with your loved ones on a deeper level. This can help you build a more fulfilling and authentic connection with them. You may want to consider having an open and honest conversation with your partner or loved ones about your desires and values, as this can help you create a more harmonious and fulfilling relationship.\\n\\nOverall, Crystal, the cards suggest that you should take a creative and intuitive approach to finding your next job, and prioritize your relationships by being open and honest with your loved ones. By doing so, you can manifest a fulfilling and abundant life that aligns with your values and desires.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an AI Clairvoyant. The retrieved context may help answer the question.\\n\\n    Context: \\n'#0 life. Connect with your senses through taste, touch, sound, smell and sight. \\nDraw on these senses to experience pleasure and deep fulfilment. \\nTreat yourself to a day spa, learn massage, enjoy a fine restaurant or spend more time with your partner. \\nDiscover different approaches to expressing yourself creatively, be it through painting, music, drama or other art forms. \\nThis may be the perfect chance to take up a new hobby that enables you to access this part of yourself. \\nThe Empress signifies abundance. You are surrounded by life’s pleasures and luxuries and have everything you need to live a \\ncomfortable lifestyle. You are in a period of growth, in which all you have dreamed of is now coming to fruition. \\nWhen The Empress appears in your Tarot readings, take a moment to reflect on the bounty that surrounds you and \\noffer gratitude for all you have created so you can continue to build on this energy and create even more abundance in \\nyour life. As the Mother Earth archetype, The Empress urges you to venture out into nature to ground your energy and be in \\nflow with the earth. Take a trip to your favorite natural setting, be it a forest, beach, mountain or lake, and sit for a \\ncouple of minutes, hours or even days to breathe in the energy that surrounds you while marveling in the beauty of your \\nsurroundings. Allow yourself the time and the space to enter a different frame of mind and receive the grounding spirit of \\nnature into your heart and consciousness. When you do this, you can reach higher planes of consciousness. When you are in \\ntune with the energy of The Empress, you will naturally take on her mothering nature. You feel a strong urge to nurture \\nand care for others, from \\n#1 relationships. The arrival of this card in a Tarot reading shows that you have a beautiful,\\n soul-honoring connection with a loved one. You may believe you have found your soul mate or life partner, \\n and the sexual energy between you both goes way beyond instant gratification and lust to something that is very\\n   spiritual and almost Tantric. While The Lovers card typically refers to a romantic tie, it can also represent a close friendship or family relationship where love, respect and compassion flow. The Lovers is a card of open communication and raw honesty. Given that the man and woman are naked, they are both willing to be in their most vulnerable states and have learned to open their hearts to one another and share their truest feelings. They shape the container from which trust and confidence can emerge, and this makes for a powerful bond between the two. In a reading, this card is a sign that by communicating openly and honestly with those you care about, you will create a harmonious and fulfilling relationship built on trust and respect. On a more personal level, The Lovers card represents getting clear about your values and beliefs. You are figuring out what you stand for and your philosophy. Having gone through the indoctrination of The Hierophant, you are now ready to establish your belief system and decide what is and what is not essential to you. It’s time to go into the big wide world and make choices for yourself, staying true to who you are and being authentic and genuine in all your endeavors. At its heart, The Lovers is about choice. The choice about who you want to be in this lifetime, \\nhow you connect with others and on what level, and about what you will and won’t \\n'\\n\\n\\n\\n    Question: Crystal, 24 year-old, single, who just left a company. She wanted to ask a question what she should do for her next job?\\n\\n    Tarot Cards: ['magician_reversed', 'empress_upright', 'moon_upright']\\n\\n    Response to the Question:\\n    \\nCrystal, the combination of cards you've drawn suggests that you should take a creative and intuitive approach to finding your next job. The Magician Reversed indicates that you may have been too focused on practicality and logic in your previous job search, and it's time to tap into your inner wisdom and creativity. The Empress Upright represents abundance and nurturing, which aligns with your desire to find a fulfilling and comfortable lifestyle. The Moon Upright symbolizes intuition and the subconscious, suggesting that you should trust your gut instincts and listen to your inner voice when exploring new career opportunities.\\n\\nTo manifest your next job, you may want to consider exploring creative fields such as art, music, or writing. These fields align with your intuition and creativity, and can provide a sense of fulfillment and abundance. Additionally, you may want to consider taking a course or workshop to develop your skills in these areas, as this can help you tap into your inner wisdom and creativity.\\n\\nIn terms of your relationships, the Lovers card suggests that you are ready to open up and communicate with your loved ones on a deeper level. This can help you build a more fulfilling and authentic connection with them. You may want to consider having an open and honest conversation with your partner or loved ones about your desires and values, as this can help you create a more harmonious and fulfilling relationship.\\n\\nOverall, Crystal, the cards suggest that you should take a creative and intuitive approach to finding your next job, and prioritize your relationships by being open and honest with your loved ones. By doing so, you can manifest a fulfilling and abundant life that aligns with your values and desires.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an AI Clairvoyant. The retrieved context may help answer the question.\\n\\n    Context: \\n'#0 life. Connect with your senses through taste, touch, sound, smell and sight. \\nDraw on these senses to experience pleasure and deep fulfilment. \\nTreat yourself to a day spa, learn massage, enjoy a fine restaurant or spend more time with your partner. \\nDiscover different approaches to expressing yourself creatively, be it through painting, music, drama or other art forms. \\nThis may be the perfect chance to take up a new hobby that enables you to access this part of yourself. \\nThe Empress signifies abundance. You are surrounded by life’s pleasures and luxuries and have everything you need to live a \\ncomfortable lifestyle. You are in a period of growth, in which all you have dreamed of is now coming to fruition. \\nWhen The Empress appears in your Tarot readings, take a moment to reflect on the bounty that surrounds you and \\noffer gratitude for all you have created so you can continue to build on this energy and create even more abundance in \\nyour life. As the Mother Earth archetype, The Empress urges you to venture out into nature to ground your energy and be in \\nflow with the earth. Take a trip to your favorite natural setting, be it a forest, beach, mountain or lake, and sit for a \\ncouple of minutes, hours or even days to breathe in the energy that surrounds you while marveling in the beauty of your \\nsurroundings. Allow yourself the time and the space to enter a different frame of mind and receive the grounding spirit of \\nnature into your heart and consciousness. When you do this, you can reach higher planes of consciousness. When you are in \\ntune with the energy of The Empress, you will naturally take on her mothering nature. You feel a strong urge to nurture \\nand care for others, from \\n#1 relationships. The arrival of this card in a Tarot reading shows that you have a beautiful,\\n soul-honoring connection with a loved one. You may believe you have found your soul mate or life partner, \\n and the sexual energy between you both goes way beyond instant gratification and lust to something that is very\\n   spiritual and almost Tantric. While The Lovers card typically refers to a romantic tie, it can also represent a close friendship or family relationship where love, respect and compassion flow. The Lovers is a card of open communication and raw honesty. Given that the man and woman are naked, they are both willing to be in their most vulnerable states and have learned to open their hearts to one another and share their truest feelings. They shape the container from which trust and confidence can emerge, and this makes for a powerful bond between the two. In a reading, this card is a sign that by communicating openly and honestly with those you care about, you will create a harmonious and fulfilling relationship built on trust and respect. On a more personal level, The Lovers card represents getting clear about your values and beliefs. You are figuring out what you stand for and your philosophy. Having gone through the indoctrination of The Hierophant, you are now ready to establish your belief system and decide what is and what is not essential to you. It’s time to go into the big wide world and make choices for yourself, staying true to who you are and being authentic and genuine in all your endeavors. At its heart, The Lovers is about choice. The choice about who you want to be in this lifetime, \\nhow you connect with others and on what level, and about what you will and won’t \\n'\\n\\n\\n\\n    Question: Crystal, 24 year-old, single, who just left a company. She wanted to ask a question what she should do for her next job?\\n\\n    Tarot Cards: ['magician_reversed', 'empress_upright', 'moon_upright']\\n\\n    Response to the Question:\\n    \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process the model outputs to find a proper answer\n",
    "answer = full_output.split('Context:')[1]\n",
    "answer_prefix = \"Response to the Question: \"\n",
    "start = answer.find(answer_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3754"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_output.find(\"Response to the Question:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an AI Clairvoyant. The retrieved context may help answer the question.\\n\\n    Context: \\n'#0 life. Connect with your senses through taste, touch, sound, smell and sight. \\nDraw on these senses to experience pleasure and deep fulfilment. \\nTreat yourself to a day spa, learn massage, enjoy a fine restaurant or spend more time with your partner. \\nDiscover different approaches to expressing yourself creatively, be it through painting, music, drama or other art forms. \\nThis may be the perfect chance to take up a new hobby that enables you to access this part of yourself. \\nThe Empress signifies abundance. You are surrounded by life’s pleasures and luxuries and have everything you need to live a \\ncomfortable lifestyle. You are in a period of growth, in which all you have dreamed of is now coming to fruition. \\nWhen The Empress appears in your Tarot readings, take a moment to reflect on the bounty that surrounds you and \\noffer gratitude for all you have created so you can continue to build on this energy and create even more abundance in \\nyour life. As the Mother Earth archetype, The Empress urges you to venture out into nature to ground your energy and be in \\nflow with the earth. Take a trip to your favorite natural setting, be it a forest, beach, mountain or lake, and sit for a \\ncouple of minutes, hours or even days to breathe in the energy that surrounds you while marveling in the beauty of your \\nsurroundings. Allow yourself the time and the space to enter a different frame of mind and receive the grounding spirit of \\nnature into your heart and consciousness. When you do this, you can reach higher planes of consciousness. When you are in \\ntune with the energy of The Empress, you will naturally take on her mothering nature. You feel a strong urge to nurture \\nand care for others, from \\n#1 relationships. The arrival of this card in a Tarot reading shows that you have a beautiful,\\n soul-honoring connection with a loved one. You may believe you have found your soul mate or life partner, \\n and the sexual energy between you both goes way beyond instant gratification and lust to something that is very\\n   spiritual and almost Tantric. While The Lovers card typically refers to a romantic tie, it can also represent a close friendship or family relationship where love, respect and compassion flow. The Lovers is a card of open communication and raw honesty. Given that the man and woman are naked, they are both willing to be in their most vulnerable states and have learned to open their hearts to one another and share their truest feelings. They shape the container from which trust and confidence can emerge, and this makes for a powerful bond between the two. In a reading, this card is a sign that by communicating openly and honestly with those you care about, you will create a harmonious and fulfilling relationship built on trust and respect. On a more personal level, The Lovers card represents getting clear about your values and beliefs. You are figuring out what you stand for and your philosophy. Having gone through the indoctrination of The Hierophant, you are now ready to establish your belief system and decide what is and what is not essential to you. It’s time to go into the big wide world and make choices for yourself, staying true to who you are and being authentic and genuine in all your endeavors. At its heart, The Lovers is about choice. The choice about who you want to be in this lifetime, \\nhow you connect with others and on what level, and about what you will and won’t \\n'\\n\\n\\n\\n    Question: Crystal, 24 year-old, single, who just left a company. She wanted to ask a question what she should do for her next job?\\n\\n    Tarot Cards: ['magician_reversed', 'empress_upright', 'lovers_upright']\\n\\n    Response to the Question:\\n    \\nCrystal, based on the Tarot cards you have pulled, it seems that you are at a crossroads in your career path. The Magician Reversed suggests that you may have been relying too heavily on your old ways of thinking and approaching your work, and now you are feeling stuck and uninspired. However, the Empress Upright and The Lovers Upright offer a glimmer of hope and guidance.\\n\\nThe Empress reminds you to connect with your senses and nurture yourself, whether that be through a spa day, cooking, or simply taking time to appreciate the beauty around you. This card also suggests that you have the ability to create abundance and luxury in your life, but you must be willing to take action and invest in yourself.\\n\\nThe Lovers Upright is a powerful card that indicates a deep connection and understanding of yourself and your desires. It suggests that you are ready to make choices that align with your values and beliefs, and to communicate openly and honestly with those around you. This card can also indicate a romantic or deeply intimate connection with someone, which may be a source of inspiration and motivation for your career path.\\n\\nOverall, Crystal, it seems that you have the opportunity to create a new and fulfilling career path that aligns with your true desires and values. By taking the time to nurture yourself and connect with your senses, and by being open and honest in your communication with others, you can create a life that brings you joy and satisfaction. Trust in yourself and your abilities, and know that you have the power to create the life you want.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def sliding_window(tarrot_data, chunck_size = 20, step_size=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Dividing text into chunks using a sliding window approach.\n",
    "\n",
    "    :param chunck_size: The number of words in each text chunk (default is 20).\n",
    "    :param step_size: The step size for the sliding window to move over the text (default is 10).\n",
    "\n",
    "    :return: A tuple of two lists: \n",
    "             - The first list contains chunks of text.\n",
    "             - The second list contains the corresponding topics for each chunk.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    chunks_topic =  []\n",
    "    sub_topics = ['upright_keywords','reverse_keywords','description','upright','reversed']\n",
    "\n",
    "    for i in tqdm(range(len(tarrot_data))):\n",
    "        card = tarrot_data[i][1]\n",
    "        upright_keywords = tarrot_data[i][2]\n",
    "        reverse_keywords = tarrot_data[i][3]\n",
    "        description = tarrot_data[i][4]\n",
    "        upright = tarrot_data[i][5]\n",
    "        reversed = tarrot_data[i][6]\n",
    "\n",
    "        topic_upright = card + '_upright'\n",
    "        text_upright = upright_keywords + ' ' + description + ' ' + upright\n",
    "        words_upright = text_upright.split()\n",
    "    \n",
    "        for i in range(0, len(words_upright) - chunck_size + 1, step_size):\n",
    "            chunks.append(\" \".join(words_upright[i:i + chunck_size]))\n",
    "            chunks_topic.append(topic_upright)\n",
    "        \n",
    "        topic_reversed = card + '_reversed'\n",
    "        text_reversed = reverse_keywords + ' ' + description + ' ' + reversed\n",
    "        words_reversed = text_reversed.split()\n",
    "    \n",
    "        for i in range(0, len(words_reversed) - chunck_size + 1, step_size):\n",
    "            chunks.append(\" \".join(words_reversed[i:i + chunck_size]))\n",
    "            chunks_topic.append(topic_reversed)\n",
    "\n",
    "    return chunks, chunks_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 6546.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "tarrot_data = pd.read_csv(\"data/tarot.csv\").values.tolist()\n",
    "\n",
    "# Create chunks of text\n",
    "chunks, chunks_topic = sliding_window(tarrot_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cos_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(np.array(a)).float()\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(np.array(b)).float()\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    \n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "def store_embedding(chunks_embedding, chunks, chunks_topic, index_name, API_key):\n",
    "    \n",
    "    \"\"\"\n",
    "    Stores embeddings with their associated text and topics into a Pinecone index.\n",
    "    :return: The created Pinecone index object.\n",
    "    \"\"\"\n",
    "    pc = Pinecone(api_key=API_key)\n",
    "    \n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=chunks_embedding.shape[1],\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud = \"aws\",\n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    )\n",
    "    \n",
    "    # index data int pinecone\n",
    "    index = pc.Index(index_name)\n",
    "    for i in tqdm(range(len(chunks_embedding))):\n",
    "        index.upsert(\n",
    "            vectors=[\n",
    "                {\n",
    "                    'id': f'vec_{i}',\n",
    "                    'values': chunks_embedding[i],\n",
    "                    'metadata': {\"text\":chunks[i], \"topic\":chunks_topic[i]}\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "    return index\n",
    "\n",
    "def retrieve_all_embedding(index, num_embed):\n",
    "    \"\"\"\n",
    "    Retrieves embeddings and their associated metadata from a Pinecone index.\n",
    "\n",
    "    :return: A Pandas DataFrame containing the embeddings and their associated metadata. \n",
    "             The DataFrame has columns 'id', 'values', and 'text'.\n",
    "    \"\"\"\n",
    "    # retrieve embeddings from vector database\n",
    "    embeddings_data = {\"id\":[], \"values\":[], \"text\":[]}\n",
    "    embeddings = index.fetch([f'vec_{i}' for i in range(num_embed)])\n",
    "    for i in range(num_embed):\n",
    "        embeddings_data[\"id\"].append(i)\n",
    "        idx = f\"vec_{i}\"\n",
    "        embeddings_data[\"text\"].append(embeddings['vectors'][idx]['metadata']['text'])\n",
    "        embeddings_data[\"values\"].append(embeddings['vectors'][idx]['values'])\n",
    "        \n",
    "    return pd.DataFrame(embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    \n",
    "    \"\"\"\n",
    "    A class for encoding text sentences into embeddings using a transformer model.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint, MAX_SEQ_LEN, device=\"cuda:0\"):\n",
    "        self.device = device\n",
    "        self.checkpoint = checkpoint\n",
    "        self.model = AutoModel.from_pretrained(checkpoint).to(self.device).half()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.sentences= None\n",
    "        self.MAX_SEQ_LEN = MAX_SEQ_LEN\n",
    "\n",
    "    def transform(self, batch):\n",
    "        tokens = self.tokenizer(batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\", max_length=self.MAX_SEQ_LEN)\n",
    "        return tokens.to(self.device)  \n",
    "\n",
    "    def get_dataloader(self, sentences, batch_size=32):\n",
    "        sentences = [\"Represent this sentence for searching relevant passages: \" + x for x in sentences]\n",
    "        self.sentences= sentences\n",
    "        dataset = Dataset.from_dict({\"text\": sentences})\n",
    "        dataset.set_transform(self.transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        return dataloader\n",
    "\n",
    "    def encode(self, sentences, show_progress_bar=False, batch_size=32):\n",
    "        dataloader = self.get_dataloader(sentences, batch_size=batch_size)\n",
    "        pbar = tqdm(dataloader) if show_progress_bar else dataloader\n",
    "        embeddings = []\n",
    "        for batch in pbar:\n",
    "            with torch.no_grad():\n",
    "                e = self.model(**batch).pooler_output\n",
    "                e = F.normalize(e, p=2, dim=1)\n",
    "                embeddings.append(e.detach().cpu().numpy())\n",
    "        embeddings = np.concatenate(embeddings, axis=0)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "\n",
    "class LlaMA2:\n",
    "    \"\"\"\n",
    "    A class for generating results given questions using a LLaMA-2 model.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint, max_seq_len = 512, device='cuda:0'):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(checkpoint)\n",
    "        self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        self.model = LlamaForCausalLM.from_pretrained(checkpoint,torch_dtype=torch.float16).to(self.device)  \n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer.encode(text, return_tensors='pt', max_length=self.max_seq_len, truncation=True)\n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        # Calculate the maximum length for the model generation\n",
    "        output_max_length = len(inputs[0]) + self.max_seq_len\n",
    "        \n",
    "        outputs = self.model.generate(inputs, max_length=output_max_length)\n",
    "        full_output =  self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # post-process the model outputs to find a proper answer\n",
    "        answer = full_output.split('Context:')[1]\n",
    "        answer_prefix = \"### Answer: \"\n",
    "        start = answer.find(answer_prefix)\n",
    "\n",
    "        # Extract the answer\n",
    "        if start != -1:\n",
    "            start += len(answer_prefix)\n",
    "            answer = answer[start:].strip()\n",
    "        else:\n",
    "            answer = \"Answer not found.\"\n",
    "        \n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 5846.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chunks embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:03<00:00,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing chunks embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunks, chunks_topic = sliding_window(tarrot_data, chunck_size = 200, step_size =50)\n",
    "\n",
    "index_name = \"astrology-bot\"\n",
    "\n",
    "embedding_model_path = 'BAAI/bge-large-en-v1.5',\n",
    "inference_model_path = 'chloeliu/llama-2-7b-chat-horoscope',\n",
    "\n",
    "print(\"Starting chunks embedding!\")\n",
    "# load LLM as embedding encoder\n",
    "model = Encoder(checkpoint='BAAI/bge-large-en-v1.5', MAX_SEQ_LEN = 256)\n",
    "# embed chunks \n",
    "chunks_embedding = model.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "\n",
    "print(\"Indexing chunks embedding!\")\n",
    "# create new index if you do not have well-build index\n",
    "try:\n",
    "    pc = Pinecone(api_key=os.environ['PINECONE'])\n",
    "    index = pc.Index(index_name)\n",
    "except:\n",
    "    index = store_embedding(chunks_embedding, chunks, chunks_topic, index_name, os.environ['PINECONE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x7f8c34929ae0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vec_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_all_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 48\u001b[0m, in \u001b[0;36mretrieve_all_embedding\u001b[0;34m(index, num_embed)\u001b[0m\n\u001b[1;32m     46\u001b[0m     embeddings_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     47\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvec_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 48\u001b[0m     embeddings_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvectors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m     embeddings_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectors\u001b[39m\u001b[38;5;124m'\u001b[39m][idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(embeddings_data)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vec_0'"
     ]
    }
   ],
   "source": [
    "df = retrieve_all_embedding(index, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from model.embedding_model import Encoder\n",
    "from model.inference_model import LlaMA2\n",
    "# from dataset.mmlu_data import load_data\n",
    "from interface.get_response import retrieve_context, ask_question\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "sys.path.insert(1, os.getcwd())\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(32)\n",
    "\n",
    "\n",
    "def get_answer(\n",
    "    embedding_model_path = \"BAAI/bge-large-en-v1.5\",\n",
    "    inference_model_path = \"chloeliu/llama-2-7b-chat-horoscope\",\n",
    "    top_k = 2,\n",
    "    question = None,\n",
    "    ):\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieves an answer for a given question or computes the QA accuracy on a test dataset using LLaMA-2-7B model.\n",
    "\n",
    "    :param embedding_model_path: Path to the embedding model.\n",
    "    :param inference_model_path: Path to the LLaMA-2-7B inference model.\n",
    "    :param top_k: The number of top contexts to retrieve for the question.\n",
    "    :param question: The question to be answered. If None, the function computes QA accuracy on a test dataset.\n",
    "\n",
    "    :return: If a question is provided, returns a tuple (answer, context). \n",
    "             If no question is provided, returns the QA accuracy as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # get embedding model and LLaMA-2-&B model\n",
    "    embedding_model = Encoder(embedding_model_path, 512)\n",
    "    inference_model = LlaMA2(inference_model_path)\n",
    "    \n",
    "    # load embeddings\n",
    "    embedding_df = pd.read_parquet(\"./data/embeddings.parquet\")\n",
    "    test_df, few_shots_df = load_data()\n",
    "    \n",
    "    \n",
    "    # merge few_shot samples into prompt\n",
    "    few_shots = []\n",
    "    for i in range(3):\n",
    "        prompt = few_shots_df.iloc[[i], :].input.values[0]\n",
    "        a, b, c, d = few_shots_df.iloc[[i], 1:-1].values[0]\n",
    "        answer = few_shots_df.iloc[[i], -1].values[0]\n",
    "        question_shot = f\"\"\"\n",
    "            Question: {prompt}\\n\n",
    "            ### Answer: {answer}\\n\n",
    "            \"\"\"\n",
    "        few_shots.append(question_shot)\n",
    "\n",
    "    few_shots = \" \\n \".join(few_shots)\n",
    "\n",
    "\n",
    "    # if a question is not provided, the function will compute QA accuracy \n",
    "    if question is None:\n",
    "        responses = []\n",
    "        right_answers = []\n",
    "        \n",
    "        for i in tqdm(range(len(test_df))):\n",
    "            \n",
    "            \n",
    "            prompt = test_df.iloc[[i], :].input.values[0]\n",
    "            a, b, c, d = test_df.iloc[[i], 1:-1].values[0]\n",
    "            right_answer = test_df.iloc[[i], -1].values[0]\n",
    "            \n",
    "            \n",
    "            right_answers.append(right_answer)\n",
    "\n",
    "\n",
    "            question = f\"\"\"\n",
    "                Question: {prompt}\n",
    "                \"\"\"\n",
    "            context = retrieve_context(question, embedding_df, embedding_model, top_k)\n",
    "            answer = ask_question(question, few_shots, context, inference_model)\n",
    "            responses.append(answer)\n",
    "            \n",
    "            if right_answer == answer:\n",
    "                print(prompt)\n",
    "                print(context)\n",
    "            \n",
    "        return (np.array(right_answers) == np.array(responses)).sum() / len(right_answers)\n",
    "            \n",
    "    else:\n",
    "        context = retrieve_context(question, embedding_df, embedding_model, top_k)\n",
    "        answer = ask_question(question, few_shots, context, inference_model)\n",
    "        \n",
    "        return answer, context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
